{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Session 6.3: Advanced Web Access through Python\n",
    "\n",
    "In the data access module, we will build upon what we have learnt in Session 2 and learn some advanced scraping:\n",
    "    1. Advanced HTML Parsing and Regular Expression\n",
    "    2. Crawling a domain\n",
    "    3. Text Recognition\n",
    "    \n",
    "This work sheets contains the in-class examples, in-class exercises as well as the homework for Session 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Advanced HTML Parsing\n",
    "### Traversing HTML document through navigation\n",
    "\n",
    "So far, we have learnt the functionality ```find_all()``` from BeautifulSoup. It helps you to find all tags based on their tag types and attributes. What if you want to find tags not based on their attributes but their location? In this case, you need to use the navigating tree from BeautifulSoup. \n",
    "\n",
    "BeautifulSoup will translate an HTML page into a tree (as shown in the previous lecture), and we can nevigate through this tree (up, down, across or diagonally) to extract reliable information. \n",
    "\n",
    "Such techniques are often used on parsing **HTML tables**. [Here is an example HTML table](https://www.w3schools.com/html/tryit.asp?filename=tryhtml_table).\n",
    "\n",
    "\n",
    "When parsing through an HTML object using navigation, we need to emphasize on the relationships between tags. There are several types of relationships:\n",
    "\n",
    "    1. Children: This is the tag that is exactly one tag below a parent. \n",
    "    2. Descendant: This can be any tag that is below a parent.\n",
    "    3. Sibling: The next tag is in the same level.\n",
    "    4. Parent: The tag that is directly one level above. \n",
    "\n",
    "\n",
    "\n",
    "### Example Navigating through a HTML table.\n",
    "Let us use the following exmaple to demonstrate this. The example webpage is [here](http://www.pythonscraping.com/pages/page3.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "img{\n",
    "\twidth:75px;\n",
    "}\n",
    "table{\n",
    "\twidth:50%;\n",
    "}\n",
    "td{\n",
    "\tmargin:10px;\n",
    "\tpadding:10px;\n",
    "}\n",
    ".wrapper{\n",
    "\twidth:800px;\n",
    "}\n",
    ".excitingNote{\n",
    "\tfont-style:italic;\n",
    "\tfont-weight:bold;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<div id=\"wrapper\">\n",
    "<img src=\"../img/gifts/logo.jpg\" style=\"float:left;\">\n",
    "<h1>Totally Normal Gifts</h1>\n",
    "<div id=\"content\">Here is a collection of totally normal, totally reasonable gifts that your friends are sure to love! Our collection is\n",
    "hand-curated by well-paid, free-range Tibetan monks.<p>\n",
    "We haven't figured out how to make online shopping carts yet, but you can send us a check to:<br>\n",
    "123 Main St.<br>\n",
    "Abuja, Nigeria\n",
    "</br>We will then send your totally amazing gift, pronto! Please include an extra $5.00 for gift wrapping.</div>\n",
    "<table id=\"giftList\">\n",
    "<tr><th>\n",
    "Item Title\n",
    "</th><th>\n",
    "Description\n",
    "</th><th>\n",
    "Cost\n",
    "</th><th>\n",
    "Image\n",
    "</th></tr>\n",
    "\n",
    "<tr id=\"gift1\" class=\"gift\"><td>\n",
    "Vegetable Basket\n",
    "</td><td>\n",
    "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
    "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
    "</td><td>\n",
    "$15.00\n",
    "</td><td>\n",
    "<img src=\"../img/gifts/img1.jpg\">\n",
    "</td></tr>\n",
    "\n",
    "<tr id=\"gift2\" class=\"gift\"><td>\n",
    "Russian Nesting Dolls\n",
    "</td><td>\n",
    "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
    "</td><td>\n",
    "$10,000.52\n",
    "</td><td>\n",
    "<img src=\"../img/gifts/img2.jpg\">\n",
    "</td></tr>\n",
    "\n",
    "<tr id=\"gift3\" class=\"gift\"><td>\n",
    "Fish Painting\n",
    "</td><td>\n",
    "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
    "</td><td>\n",
    "$10,005.00\n",
    "</td><td>\n",
    "<img src=\"../img/gifts/img3.jpg\">\n",
    "</td></tr>\n",
    "\n",
    "<tr id=\"gift4\" class=\"gift\"><td>\n",
    "Dead Parrot\n",
    "</td><td>\n",
    "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
    "</td><td>\n",
    "$0.50\n",
    "</td><td>\n",
    "<img src=\"../img/gifts/img4.jpg\">\n",
    "</td></tr>\n",
    "\n",
    "<tr id=\"gift5\" class=\"gift\"><td>\n",
    "Mystery Box\n",
    "</td><td>\n",
    "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
    "</td><td>\n",
    "$1.50\n",
    "</td><td>\n",
    "<img src=\"../img/gifts/img6.jpg\">\n",
    "</td></tr>\n",
    "</table>\n",
    "</p>\n",
    "<div id=\"footer\">\n",
    "&copy; Totally Normal Gifts, Inc. <br>\n",
    "+234 (617) 863-0736\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "table = soup.find(\"table\", {\"id\": \"giftList\"})\n",
    "\n",
    "print(table.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for child in table.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(table.tr)\n",
    "\n",
    "for sibling in table.tr.next_siblings:\n",
    "    print(sibling)\n",
    "\n",
    "print(table.tr.parent == table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression\n",
    "\n",
    "So far, we rely on the structure provided by ```BeautifulSoup``` to transform a HTML page into a tree structure and we can (1) use ```find_all()``` to search through the tree and (2) navigate the tree through different relationships. \n",
    "\n",
    "Another approach is to treat all HTML page as a text file. In this case, what we need is a way to extract valuable information from a text file. For instance, in previous exercise, you get the cost as \\$1.50, but what you really need is the number 1.5. How could you change the string \\$1.50 into a number 1.5? \n",
    "\n",
    "The answer is **Regular Expression**. Regular expressions are so called because they are used to identify regular string. Basically, what regular expression can do is either (1) \"Yes, this string you have given me follows the rules and I will return it\" or \"This string does not follow the rules, and I will discard it.\" In this way, regular expression can be used to **mask out** any unnecessary part of a string text and allow people to extract only the valuable information. \n",
    "\n",
    "Regular Expressions have a set of symbols that you can use to define any particular rule for a string. For the purpose of this course, we are only covering a small subset of symboles:\n",
    "    \n",
    "1. ```[]```: Match anything inside the square brackets for ONE character position, once and only once. For example, ```[12]``` means match the target to 1 and if that does not match then match the target to 2 while ```[0123456789]``` means match to any character in the range 0 to 9.\n",
    "\n",
    "2. ```-```: The - (dash) inside square brackets is the 'range separator' and allows us to define a range, in our example above of ```[0123456789]``` we could rewrite it as [0-9]. You can define more than one range inside a list, for example, ```[0-9A-C]``` means check for 0 to 9 and A to C (but not a to c).\n",
    "\n",
    "3. ```^```: The ^ (circumflex or caret) inside square brackets negates the expression (we will see an alternate use for the circumflex/caret outside square brackets later), for example, ```[^Ff]``` means anything except upper or lower case F and ```[^a-z]``` means everything except lower case a to z. The ^ (circumflex or caret) when not used inside square brackets (where it has a diffent meaning) means look only at the beginning of the target string, for example, ```^Win``` will not find Windows in STRING1 but ```^Moz``` will find Mozilla.\n",
    "\n",
    "4. ```$```: The dollar signs means look only at the end of the target string, for example, ```fox$``` will find a match in 'silver fox' since it appears at the end of the string but not in 'the fox jumped over the moon'.\n",
    "\n",
    "5. ```.```: The . (period) means any character(s) in this position, for example, ```ton.``` will find tons, tone and tonn in tonneau but not wanton because it has no following character.\n",
    "\n",
    "6. ```?```: The ? (question mark) matches when the preceding character occurs 0 or 1 times only, for example, ```colou?r``` will find both color (u is found 0 times) and colour (u is found 1 time).\n",
    "\n",
    "7. ```*```: The * (asterisk or star) matches when the preceding character occurs 0 or more times, for example, ```tre*``` will find tree (e is found 2 times) and tread (e is found 1 time) and trough (e is found 0 times and thus returns a match only on the tr).\n",
    "\n",
    "8. ```+```: The + (plus) matches when the preceding character occurs 1 or more times, for example, ```tre+``` will find tree (e is found 2 times) and tread (e is found 1 time) but NOT trough (0 times).\n",
    "\n",
    "9. ```{n}```: Matches when the preceding character, or character range, occurs n times exactly, for example, to find a local phone number we could use ```[0-9]{3}-[0-9]{4}``` which would find any number of the form 123-4567. Value is enclosed in braces (curly brackets).\n",
    "\n",
    "10. ```(A|B)```: Matches either A or B but not both. \n",
    "\n",
    "11. ```(?!x)```: Does not contain x. \n",
    "\n",
    "### Example Regular expression examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 15), match='abc102321321abc'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.search(\"abc.*abc\", \"abc102321321abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denniszhang@wustl.edu is a valid email\n",
      "non@xxx is not a valid email\n",
      "@wustl.edu is not a valid email\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Email rule: detect whether an address follows the following rule:\n",
    "#    string + @ + string + . + (com, org, edu or net)\n",
    "\n",
    "valid_email = \"denniszhang@wustl.edu\"\n",
    "invalid_email_1 = \"non@xxx\"\n",
    "invalid_email_2 = \"@wustl.edu\"\n",
    "\n",
    "for email in [valid_email, invalid_email_1, invalid_email_2]:\n",
    "    if re.search(\"[A-Za-z0-9\\._]+@[A-Za-z]+\\.(com|org|edu|net)\", email) is None:\n",
    "        print(\"%s is not a valid email\" % email)\n",
    "    else:\n",
    "        print(\"%s is a valid email\" % email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Regular expression with BeautifulSoup\n",
    "\n",
    "We can combine regular expression with BeautifulSoup. Remember that ```find_all(\"a\", {\"class\", \"sister\"})``` allows us to find all tag with ```<a></a>``` that has attribute ```class``` equal to ```sister```. Now, instead of putting an exact string for the attribute, we can match the attribute based on regular expressions, using ```re.compile()```.\n",
    "\n",
    "In the following example, we try to get all the url address about each sister from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
    "<a href=\"hahaha...\" id=\"link3\">This is not a sister</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "sister_urls = soup.find_all(\"a\", {\"href\":re.compile(\"http://example.com/[A-Aa-z]+\")})\n",
    "for url in sister_urls:\n",
    "    print(url[\"href\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling a domain\n",
    "### Finding links in a website and crawling through links\n",
    "\n",
    "So far, we focused on how to extract information from a single webpage. Now, we are looking at how we could crawl a domain. The process of crawling a domain can be generally divided into\n",
    "\n",
    "1. Find a first landing page\n",
    "2. Get all crawlable links from that landing page save it to a set N\n",
    "3. **Choose** one link from N and takes that link out of N.\n",
    "4. Repeat Step 1 - 3 until we deplete all links in N. \n",
    "\n",
    "Depending on how we choose which link to follow, the search process can be quite different. In particular, there are two fundemental types of searchs:\n",
    "\n",
    "1. **Breadth First Search**: BFS is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root and explores the neighbor nodes first, before moving to the next level neighbors.\n",
    "2. **Depth First Search**: DFS is an algorithm for traversing or searching tree or graph data structures. One starts at the root and explores as far as possible along each branch before backtracking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.2.1 BFS vs DFS.\n",
    "\n",
    "Let us consider the following tree structure:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1f/Depth-first-tree.svg\">\n",
    "\n",
    "Suppose that we start at the root of the tree (Node 1) and use **BFS**. In this case, BFS, will first explore all neighbors and then continue. So the sequence of searchers will be:\n",
    "\n",
    "1. Layer 0: Node 1\n",
    "2. Layer 1: Node 2, 7, 8\n",
    "3. Layer 2: Node 3, 6, 9, 12\n",
    "4. Layer 3: Node 4, 5, 10, 11\n",
    "\n",
    "So the final sequence is [1, 2, 7, 8, 3, 6, 9, 12, 4, 5, 10, 11]\n",
    "\n",
    "On the other hand, if we use **DFS**, the sequence will be:\n",
    "\n",
    "1. Path 1: Node 1 -> Node 2 -> Node 3 -> Node 4, Node 3 -> Node 5, Node 2 -> Node 6\n",
    "2. Path 2: Node 1 -> Node 7, \n",
    "3. Path 3: Node 1 -> Node 8 -> Node 9 -> Node 10, Node 9 -> Node 11, Node 8 ->  Node 12.\n",
    "\n",
    "So the final sequence is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "Depending on the purpose of crawling links, we will favor different links. For example, let us consider the following 2 questions:\n",
    "\n",
    "1. Question: Go to Linkedin and find all people who are 2-step away from John. \n",
    "2. Question: Go to Linkedin and find a person who is 5-step away from John and important to John's career so that you can recommend him/her to John. \n",
    "\n",
    "### BFS vs DFS:\n",
    "How many steps it may take if we answer these two questions using different search algorithms? Suppose that an average person has 200 connections and among all people who are 5-step away from John, 10% of them are important to John."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
